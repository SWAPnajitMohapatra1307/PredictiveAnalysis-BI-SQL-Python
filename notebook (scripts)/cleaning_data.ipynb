{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c8bbe8",
   "metadata": {},
   "source": [
    "STEP-1:IMPORT ALL ESSENTIAL LIBRARIES INTO NOTEBOOK\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ebe05fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6ee1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year Month_Name      Date           State         Vehicle_Class  \\\n",
      "0  2014.0        jan  1/1/2014  Andhra Pradesh     ADAPTED VEHICLE     \n",
      "1  2014.0        jan  1/1/2014  ANDHRA PRADESH  AGRICULTURAL TRACTOR   \n",
      "2  2014.0        jan  1/1/2014  ANDHRA PRADESH           AMBULANCE     \n",
      "3  2014.0        jan  1/1/2014  Andhra Pradesh   ARTICULATED VEHICLE   \n",
      "4  2014.0        jan  1-1-2014  Andhra Pradesh                 BUS     \n",
      "\n",
      "  Vehicle_Category Vehicle_Type  EV_Sales_Quantity  \n",
      "0           Others       Others                0.0  \n",
      "1           Others       Others                0.0  \n",
      "2           Others       Others                0.0  \n",
      "3           Others       Others                0.0  \n",
      "4              Bus          Bus                0.0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/CONFUSED CRUSADER/Downloads/ev_messy_inconsistent.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9114e1d",
   "metadata": {},
   "source": [
    "as you can see the table above , the data present in this CSV seems to be inconsistent,presence of duplicates, spacing and null values\n",
    "in order to tacke this situation , we need to clean data properly in order to proceed into analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c4538",
   "metadata": {},
   "source": [
    "STEP-2 : DATA CLEANING \n",
    "1) convert float data type into integer datatype in Year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3d7282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96895 entries, 0 to 96894\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Year               96895 non-null  int64  \n",
      " 1   Month_Name         94957 non-null  object \n",
      " 2   Date               94957 non-null  object \n",
      " 3   State              94957 non-null  object \n",
      " 4   Vehicle_Class      94957 non-null  object \n",
      " 5   Vehicle_Category   94957 non-null  object \n",
      " 6   Vehicle_Type       94957 non-null  object \n",
      " 7   EV_Sales_Quantity  94957 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## in Year section, the value is stored in float format(ex-2014.0), we need to convert it into int format(ex-2014)\n",
    "df['Year'] = df['Year'].fillna(0).astype(int)#.fillna(0) helps fill value as 0 in place of null value so that it can be converted into int format\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cca5d6",
   "metadata": {},
   "source": [
    "2) remove any duplicates, null values present inside dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a3c40b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94953 entries, 0 to 96894\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Year               94953 non-null  int64  \n",
      " 1   Month_Name         94953 non-null  object \n",
      " 2   Date               94953 non-null  object \n",
      " 3   State              94953 non-null  object \n",
      " 4   Vehicle_Class      94953 non-null  object \n",
      " 5   Vehicle_Category   94953 non-null  object \n",
      " 6   Vehicle_Type       94953 non-null  object \n",
      " 7   EV_Sales_Quantity  94953 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 6.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()#removes duplicate values in all columns\n",
    "df = df.dropna()#removes null values in all columns\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20fad47",
   "metadata": {},
   "source": [
    "after observation of above table ,it confirms that the duplicate/null values are removed (considering that all the columns possess same non null values)\n",
    "\n",
    "but there are still minor cleaning/modifications required in order to proceed further in  analysis of this dataset\n",
    "more like \"in depth cleaning\" of each column(any minor casing errors,unnecessary spaces, inconsistent format )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97377660",
   "metadata": {},
   "source": [
    "3) final touches in terms of data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d0bc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andhra Pradesh' 'Arunachal Pradesh' 'Assam' 'Andaman & Nicobar Island'\n",
      " 'Bihar' 'Chhattisgarh' 'Chandigarh' 'Dnh And Dd' 'Delhi' 'Goa' 'Gujarat'\n",
      " 'Himachal Pradesh' 'Haryana' 'Jharkhand' 'Karnataka' 'Kerala' 'Ladakh'\n",
      " 'Maharashtra' 'Meghalaya' 'Madhya Pradesh' 'Mizoram' 'Nagaland' 'Odisha'\n",
      " 'Punjab' 'Puducherry' 'Rajasthan' 'Sikkim' 'Tamil Nadu' 'Tripura'\n",
      " 'Uttarakhand' 'Uttar Pradesh' 'West Bengal' 'Jammu And Kashmir' 'Manipur']\n"
     ]
    }
   ],
   "source": [
    "df['State'] = df['State'].str.strip().str.title()#removes unncesssary spaces in between and \n",
    "print(df['State'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1af9a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n"
     ]
    }
   ],
   "source": [
    "df['Month_Name'] = df['Month_Name'].str.strip().str.capitalize()#removes unncesssary spaces in between and converts first letter to capital and rest to small\n",
    "print(df['Month_Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b733925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1/1/2014' '1/1/2015' '1/1/2016' '1/1/2017' '1/1/2018' '1/1/2019'\n",
      " '1/1/2020' '1/1/2021' '1/1/2022' '1/1/2023' '1/1/2024' '1/2/2014'\n",
      " '2/1/2014' '2/1/2015' '1/2/2015' '2/1/2016' '1/2/2016' '2/1/2017'\n",
      " '1/2/2017' '2/1/2018' '1/2/2018' '1/2/2019' '2/1/2019' '2/1/2020'\n",
      " '1/2/2020' '2/1/2021' '1/2/2021' '2/1/2022' '1/2/2022' '2/1/2023'\n",
      " '1/2/2023' '3/1/2014' '1/3/2014' '3/1/2015' '1/3/2015' '1/3/2016'\n",
      " '3/1/2016' '3/1/2017' '1/3/2017' '3/1/2018' '1/3/2018' '3/1/2019'\n",
      " '1/3/2019' '3/1/2020' '1/3/2020' '3/1/2021' '1/3/2021' '3/1/2022'\n",
      " '1/3/2022' '3/1/2023' '1/3/2023' '4/1/2014' '1/4/2014' '4/1/2015'\n",
      " '1/4/2015' '4/1/2016' '1/4/2016' '4/1/2017' '1/4/2017' '4/1/2018'\n",
      " '1/4/2018' '4/1/2019' '1/4/2019' '4/1/2020' '1/4/2020' '4/1/2021'\n",
      " '1/4/2021' '4/1/2022' '1/4/2022' '4/1/2023' '1/4/2023' '5/1/2014'\n",
      " '1/5/2014' '5/1/2015' '1/5/2015' '5/1/2016' '1/5/2016' '5/1/2017'\n",
      " '1/5/2017' '5/1/2018' '1/5/2018' '5/1/2019' '1/5/2019' '5/1/2020'\n",
      " '1/5/2020' '5/1/2021' '1/5/2021' '5/1/2022' '1/5/2022' '5/1/2023'\n",
      " '1/5/2023' '6/1/2014' '1/6/2014' '6/1/2015' '1/6/2015' '6/1/2016'\n",
      " '1/6/2016' '6/1/2017' '1/6/2017' '6/1/2018' '1/6/2018' '6/1/2019'\n",
      " '1/6/2019' '6/1/2020' '1/6/2020' '6/1/2021' '1/6/2021' '6/1/2022'\n",
      " '1/6/2022' '6/1/2023' '1/6/2023' '7/1/2014' '1/7/2014' '7/1/2015'\n",
      " '1/7/2015' '1/7/2016' '7/1/2016' '7/1/2017' '1/7/2017' '7/1/2018'\n",
      " '1/7/2018' '7/1/2019' '1/7/2019' '7/1/2020' '1/7/2020' '7/1/2021'\n",
      " '1/7/2021' '7/1/2022' '1/7/2022' '7/1/2023' '1/7/2023' '8/1/2014'\n",
      " '1/8/2014' '8/1/2015' '1/8/2015' '8/1/2016' '1/8/2016' '8/1/2017'\n",
      " '1/8/2017' '8/1/2018' '1/8/2018' '8/1/2019' '1/8/2019' '8/1/2020'\n",
      " '1/8/2020' '8/1/2021' '1/8/2021' '8/1/2022' '1/8/2022' '8/1/2023'\n",
      " '1/8/2023' '9/1/2014' '1/9/2014' '9/1/2015' '1/9/2015' '9/1/2016'\n",
      " '1/9/2016' '9/1/2017' '1/9/2017' '9/1/2018' '1/9/2018' '9/1/2019'\n",
      " '1/9/2019' '9/1/2020' '1/9/2020' '9/1/2021' '1/9/2021' '9/1/2022'\n",
      " '1/9/2022' '9/1/2023' '1/9/2023' '10/1/2014' '1/10/2014' '10/1/2015'\n",
      " '1/10/2015' '10/1/2016' '1/10/2016' '10/1/2017' '1/10/2017' '10/1/2018'\n",
      " '1/10/2018' '10/1/2019' '1/10/2019' '10/1/2020' '1/10/2020' '10/1/2021'\n",
      " '1/10/2021' '10/1/2022' '1/10/2022' '10/1/2023' '1/10/2023' '11/1/2014'\n",
      " '1/11/2014' '11/1/2015' '1/11/2015' '11/1/2016' '1/11/2016' '11/1/2017'\n",
      " '1/11/2017' '11/1/2018' '1/11/2018' '11/1/2019' '1/11/2019' '11/1/2020'\n",
      " '1/11/2020' '11/1/2021' '1/11/2021' '11/1/2022' '1/11/2022' '1/11/2023'\n",
      " '11/1/2023' '12/1/2014' '1/12/2014' '12/1/2015' '1/12/2015' '12/1/2016'\n",
      " '1/12/2016' '12/1/2017' '1/12/2017' '12/1/2018' '1/12/2018' '12/1/2019'\n",
      " '1/12/2019' '12/1/2020' '1/12/2020' '12/1/2021' '1/12/2021' '12/1/2022'\n",
      " '1/12/2022' '12/1/2023' '1/12/2023']\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = df['Date'].apply(lambda x: x.replace('-', '/') if '-' in x else x)#replaces - with / in date column using replace function inside lambda function(for condition based replacement) \n",
    "print(df['Date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6721ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year Month_Name      Date           State         Vehicle_Class  \\\n",
      "0  2014        Jan  1/1/2014  Andhra Pradesh       Adapted Vehicle   \n",
      "1  2014        Jan  1/1/2014  Andhra Pradesh  Agricultural Tractor   \n",
      "2  2014        Jan  1/1/2014  Andhra Pradesh             Ambulance   \n",
      "3  2014        Jan  1/1/2014  Andhra Pradesh   Articulated Vehicle   \n",
      "4  2014        Jan  1/1/2014  Andhra Pradesh                   Bus   \n",
      "\n",
      "  Vehicle_Category Vehicle_Type  EV_Sales_Quantity  \n",
      "0           Others       Others                0.0  \n",
      "1           Others       Others                0.0  \n",
      "2           Others       Others                0.0  \n",
      "3           Others       Others                0.0  \n",
      "4              Bus          Bus                0.0  \n"
     ]
    }
   ],
   "source": [
    "df['Vehicle_Class'] = df['Vehicle_Class'].str.strip().str.title()#removes unncesssary spaces in between and converts first letter to capital and rest to smal\n",
    "df['Vehicle_Category'] = df['Vehicle_Category'].str.strip().str.title()#removes unncesssary spaces in between and converts first letter to capital and rest to small\n",
    "df['Vehicle_Type'] = df['Vehicle_Type'].str.strip().str.title()#removes unncesssary spaces in between and converts first letter to capital and rest to small\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0184b09",
   "metadata": {},
   "source": [
    "now we can say that the above data is properly cleaned and it is ready for futher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6f22bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ev_clean_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
